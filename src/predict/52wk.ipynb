{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds_feat = pd.read_csv('../../data/processed_train_feat.csv')\n",
    "train_ds_targ = pd.read_csv('../../data/processed_train_targ.csv')\n",
    "\n",
    "test_ds_feat = pd.read_csv('../../data/processed_test_feat.csv')\n",
    "test_ds_targ = pd.read_csv('../../data/processed_test_targ.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40\n"
     ]
    }
   ],
   "source": [
    "len(train_ds_targ.iloc[:, 1:].values) == len(train_ds_feat.iloc[:, 1:].values)\n",
    "print(len(train_ds_feat.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyDataset(Dataset):\n",
    "    def __init__(self, feat, targ):\n",
    "        self.feat = feat.iloc[:, 1:].values\n",
    "        self.targ = targ.iloc[:, 1:].values\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.feat)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        feat = torch.FloatTensor(self.feat[idx])\n",
    "        targ = torch.FloatTensor(self.targ[idx])\n",
    "        return feat, targ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = MyDataset(train_ds_feat, train_ds_targ)\n",
    "test_ds = MyDataset(test_ds_feat, test_ds_targ)\n",
    "\n",
    "train_dl = DataLoader(train_ds, batch_size=1, shuffle=True)\n",
    "test_dl = DataLoader(test_ds, batch_size=1, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n"
     ]
    }
   ],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Using {device} device\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NeuralNetwork(\n",
      "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "  (linear_relu_stack): Sequential(\n",
      "    (0): Linear(in_features=39, out_features=512, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=512, out_features=2, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self, input_size, output_size):\n",
    "        super(NeuralNetwork, self).__init__()\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.linear_relu_stack = nn.Sequential(\n",
    "            nn.Linear(input_size, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, output_size)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.flatten(x)\n",
    "        logits = self.linear_relu_stack(x)\n",
    "        return logits\n",
    "\n",
    "model = NeuralNetwork(len(train_ds_feat.columns)-1, len(train_ds_targ.columns)-1).to(device)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(dataloader, model, loss_fn, optimizer):\n",
    "    size = len(dataloader.dataset)\n",
    "    model.train()\n",
    "    for batch, (X, y) in enumerate(dataloader):\n",
    "        X, y = X.to(device), y.to(device)\n",
    "\n",
    "        # Compute prediction error\n",
    "        pred = model(X)\n",
    "        loss = loss_fn(pred, y)\n",
    "\n",
    "        # Backpropagation\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if batch % 100 == 0:\n",
    "            loss, current = loss.item(), batch * len(X)\n",
    "            print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(dataloader, model, loss_fn):\n",
    "    size = len(dataloader.dataset)\n",
    "    num_batches = len(dataloader)\n",
    "    model.eval()\n",
    "    test_loss, correct = 0, 0\n",
    "    with torch.no_grad():\n",
    "        for X, y in dataloader:\n",
    "            X, y = X.to(device), y.to(device)\n",
    "            pred = model(X)\n",
    "            test_loss += loss_fn(pred, y).item()\n",
    "            correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
    "    test_loss /= num_batches\n",
    "    correct /= size\n",
    "    print(f\"Test Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "-------------------------------\n",
      "loss: 120.560211  [    0/ 1485]\n",
      "loss: 45.529320  [  100/ 1485]\n",
      "loss: 49.926876  [  200/ 1485]\n",
      "loss: 217.942169  [  300/ 1485]\n",
      "loss: 115.530121  [  400/ 1485]\n",
      "loss: 42.695717  [  500/ 1485]\n",
      "loss: 235.472092  [  600/ 1485]\n",
      "loss: 174.595245  [  700/ 1485]\n",
      "loss: 104.867661  [  800/ 1485]\n",
      "loss: 52.660538  [  900/ 1485]\n",
      "loss: 233.681488  [ 1000/ 1485]\n",
      "loss: 289.930695  [ 1100/ 1485]\n",
      "loss: 35.166996  [ 1200/ 1485]\n",
      "loss: 112.259674  [ 1300/ 1485]\n",
      "loss: 172.570663  [ 1400/ 1485]\n",
      "Test Error: \n",
      " Accuracy: 0.0%, Avg loss: 161.628093 \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "loss: 72.218475  [    0/ 1485]\n",
      "loss: 49.862251  [  100/ 1485]\n",
      "loss: 23.159868  [  200/ 1485]\n",
      "loss: 210.594574  [  300/ 1485]\n",
      "loss: 271.214752  [  400/ 1485]\n",
      "loss: 145.569794  [  500/ 1485]\n",
      "loss: 139.796448  [  600/ 1485]\n",
      "loss: 71.326935  [  700/ 1485]\n",
      "loss: 209.242584  [  800/ 1485]\n",
      "loss: 135.485962  [  900/ 1485]\n",
      "loss: 148.723541  [ 1000/ 1485]\n",
      "loss: 81.837822  [ 1100/ 1485]\n",
      "loss: 167.661392  [ 1200/ 1485]\n",
      "loss: 267.161438  [ 1300/ 1485]\n",
      "loss: 74.912697  [ 1400/ 1485]\n",
      "Test Error: \n",
      " Accuracy: 0.0%, Avg loss: 163.000730 \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "loss: 208.128967  [    0/ 1485]\n",
      "loss: 85.373077  [  100/ 1485]\n",
      "loss: 59.782051  [  200/ 1485]\n",
      "loss: 192.808548  [  300/ 1485]\n",
      "loss: 52.146477  [  400/ 1485]\n",
      "loss: 54.704575  [  500/ 1485]\n",
      "loss: 23.722439  [  600/ 1485]\n",
      "loss: 32.606277  [  700/ 1485]\n",
      "loss: 164.976349  [  800/ 1485]\n",
      "loss: 71.979736  [  900/ 1485]\n",
      "loss: 224.562531  [ 1000/ 1485]\n",
      "loss: 55.674335  [ 1100/ 1485]\n",
      "loss: 86.821533  [ 1200/ 1485]\n",
      "loss: 108.557701  [ 1300/ 1485]\n",
      "loss: 114.015671  [ 1400/ 1485]\n",
      "Test Error: \n",
      " Accuracy: 0.0%, Avg loss: 161.606686 \n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "loss: 38.169769  [    0/ 1485]\n",
      "loss: 12.822869  [  100/ 1485]\n",
      "loss: 79.797119  [  200/ 1485]\n",
      "loss: 31.580273  [  300/ 1485]\n",
      "loss: 88.786430  [  400/ 1485]\n",
      "loss: 35.888088  [  500/ 1485]\n",
      "loss: 448.966125  [  600/ 1485]\n",
      "loss: 222.684570  [  700/ 1485]\n",
      "loss: 134.075623  [  800/ 1485]\n",
      "loss: 102.889847  [  900/ 1485]\n",
      "loss: 78.004059  [ 1000/ 1485]\n",
      "loss: 156.740250  [ 1100/ 1485]\n",
      "loss: 134.874222  [ 1200/ 1485]\n",
      "loss: 91.601456  [ 1300/ 1485]\n",
      "loss: 20.411610  [ 1400/ 1485]\n",
      "Test Error: \n",
      " Accuracy: 0.0%, Avg loss: 161.619623 \n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "loss: 345.270355  [    0/ 1485]\n",
      "loss: 60.234024  [  100/ 1485]\n",
      "loss: 18.681641  [  200/ 1485]\n",
      "loss: 267.144745  [  300/ 1485]\n",
      "loss: 44.178574  [  400/ 1485]\n",
      "loss: 62.424309  [  500/ 1485]\n",
      "loss: 20.846748  [  600/ 1485]\n",
      "loss: 27.709759  [  700/ 1485]\n",
      "loss: 25.075794  [  800/ 1485]\n",
      "loss: 116.980682  [  900/ 1485]\n",
      "loss: 68.251633  [ 1000/ 1485]\n",
      "loss: 62.705124  [ 1100/ 1485]\n",
      "loss: 327.082947  [ 1200/ 1485]\n",
      "loss: 103.844559  [ 1300/ 1485]\n",
      "loss: 232.394440  [ 1400/ 1485]\n",
      "Test Error: \n",
      " Accuracy: 0.0%, Avg loss: 170.825853 \n",
      "\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "loss: 286.031708  [    0/ 1485]\n",
      "loss: 36.263401  [  100/ 1485]\n",
      "loss: 49.015602  [  200/ 1485]\n",
      "loss: 636.024658  [  300/ 1485]\n",
      "loss: 51.445259  [  400/ 1485]\n",
      "loss: 114.638329  [  500/ 1485]\n",
      "loss: 68.242783  [  600/ 1485]\n",
      "loss: 404.273010  [  700/ 1485]\n",
      "loss: 44.629028  [  800/ 1485]\n",
      "loss: 197.655640  [  900/ 1485]\n",
      "loss: 173.110504  [ 1000/ 1485]\n",
      "loss: 53.551353  [ 1100/ 1485]\n",
      "loss: 180.149292  [ 1200/ 1485]\n",
      "loss: 37.661018  [ 1300/ 1485]\n",
      "loss: 71.862900  [ 1400/ 1485]\n",
      "Test Error: \n",
      " Accuracy: 0.0%, Avg loss: 161.647931 \n",
      "\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "loss: 47.940449  [    0/ 1485]\n",
      "loss: 190.548584  [  100/ 1485]\n",
      "loss: 68.783401  [  200/ 1485]\n",
      "loss: 930.040222  [  300/ 1485]\n",
      "loss: 74.723831  [  400/ 1485]\n",
      "loss: 138.043243  [  500/ 1485]\n",
      "loss: 81.565132  [  600/ 1485]\n",
      "loss: 180.162476  [  700/ 1485]\n",
      "loss: 88.525360  [  800/ 1485]\n",
      "loss: 261.788788  [  900/ 1485]\n",
      "loss: 224.573975  [ 1000/ 1485]\n",
      "loss: 66.830109  [ 1100/ 1485]\n",
      "loss: 48.702740  [ 1200/ 1485]\n",
      "loss: 181.043365  [ 1300/ 1485]\n",
      "loss: 184.296494  [ 1400/ 1485]\n",
      "Test Error: \n",
      " Accuracy: 0.0%, Avg loss: 161.566642 \n",
      "\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "loss: 93.514359  [    0/ 1485]\n",
      "loss: 27.708326  [  100/ 1485]\n",
      "loss: 72.633835  [  200/ 1485]\n",
      "loss: 65.248642  [  300/ 1485]\n",
      "loss: 76.013641  [  400/ 1485]\n",
      "loss: 62.650814  [  500/ 1485]\n",
      "loss: 86.378944  [  600/ 1485]\n",
      "loss: 99.759903  [  700/ 1485]\n",
      "loss: 110.761345  [  800/ 1485]\n",
      "loss: 68.410538  [  900/ 1485]\n",
      "loss: 98.375534  [ 1000/ 1485]\n",
      "loss: 50.735950  [ 1100/ 1485]\n",
      "loss: 133.276154  [ 1200/ 1485]\n",
      "loss: 265.830261  [ 1300/ 1485]\n",
      "loss: 339.909546  [ 1400/ 1485]\n",
      "Test Error: \n",
      " Accuracy: 0.0%, Avg loss: 161.634421 \n",
      "\n",
      "Epoch 9\n",
      "-------------------------------\n",
      "loss: 129.215485  [    0/ 1485]\n",
      "loss: 30.725752  [  100/ 1485]\n",
      "loss: 26.306023  [  200/ 1485]\n",
      "loss: 212.764877  [  300/ 1485]\n",
      "loss: 251.708252  [  400/ 1485]\n",
      "loss: 142.050323  [  500/ 1485]\n",
      "loss: 78.231133  [  600/ 1485]\n",
      "loss: 99.941299  [  700/ 1485]\n",
      "loss: 50.614925  [  800/ 1485]\n",
      "loss: 16.194756  [  900/ 1485]\n",
      "loss: 66.600311  [ 1000/ 1485]\n",
      "loss: 51.378086  [ 1100/ 1485]\n",
      "loss: 496.728699  [ 1200/ 1485]\n",
      "loss: 77.967697  [ 1300/ 1485]\n",
      "loss: 39.353252  [ 1400/ 1485]\n",
      "Test Error: \n",
      " Accuracy: 0.0%, Avg loss: 161.566657 \n",
      "\n",
      "Epoch 10\n",
      "-------------------------------\n",
      "loss: 426.819214  [    0/ 1485]\n",
      "loss: 260.577637  [  100/ 1485]\n",
      "loss: 58.067245  [  200/ 1485]\n",
      "loss: 18.676125  [  300/ 1485]\n",
      "loss: 63.770821  [  400/ 1485]\n",
      "loss: 74.605492  [  500/ 1485]\n",
      "loss: 23.338449  [  600/ 1485]\n",
      "loss: 97.336578  [  700/ 1485]\n",
      "loss: 54.352768  [  800/ 1485]\n",
      "loss: 180.630707  [  900/ 1485]\n",
      "loss: 52.383419  [ 1000/ 1485]\n",
      "loss: 61.351917  [ 1100/ 1485]\n",
      "loss: 1249.275391  [ 1200/ 1485]\n",
      "loss: 133.018997  [ 1300/ 1485]\n",
      "loss: 177.017853  [ 1400/ 1485]\n",
      "Test Error: \n",
      " Accuracy: 0.0%, Avg loss: 162.302428 \n",
      "\n",
      "Epoch 11\n",
      "-------------------------------\n",
      "loss: 76.332146  [    0/ 1485]\n",
      "loss: 179.434082  [  100/ 1485]\n",
      "loss: 195.431732  [  200/ 1485]\n",
      "loss: 89.679771  [  300/ 1485]\n",
      "loss: 164.143326  [  400/ 1485]\n",
      "loss: 59.075676  [  500/ 1485]\n",
      "loss: 114.893158  [  600/ 1485]\n",
      "loss: 151.501678  [  700/ 1485]\n",
      "loss: 394.658142  [  800/ 1485]\n",
      "loss: 67.902191  [  900/ 1485]\n",
      "loss: 77.120636  [ 1000/ 1485]\n",
      "loss: 144.818756  [ 1100/ 1485]\n",
      "loss: 271.305176  [ 1200/ 1485]\n",
      "loss: 162.861572  [ 1300/ 1485]\n",
      "loss: 173.353485  [ 1400/ 1485]\n",
      "Test Error: \n",
      " Accuracy: 0.0%, Avg loss: 161.726318 \n",
      "\n",
      "Epoch 12\n",
      "-------------------------------\n",
      "loss: 311.267059  [    0/ 1485]\n",
      "loss: 70.201736  [  100/ 1485]\n",
      "loss: 86.052277  [  200/ 1485]\n",
      "loss: 87.850830  [  300/ 1485]\n",
      "loss: 133.678070  [  400/ 1485]\n",
      "loss: 270.146851  [  500/ 1485]\n",
      "loss: 359.623230  [  600/ 1485]\n",
      "loss: 173.087585  [  700/ 1485]\n",
      "loss: 78.459137  [  800/ 1485]\n",
      "loss: 129.135025  [  900/ 1485]\n",
      "loss: 105.984200  [ 1000/ 1485]\n",
      "loss: 124.999802  [ 1100/ 1485]\n",
      "loss: 120.038696  [ 1200/ 1485]\n",
      "loss: 72.896729  [ 1300/ 1485]\n",
      "loss: 65.765701  [ 1400/ 1485]\n",
      "Test Error: \n",
      " Accuracy: 0.0%, Avg loss: 161.778641 \n",
      "\n",
      "Epoch 13\n",
      "-------------------------------\n",
      "loss: 71.788956  [    0/ 1485]\n",
      "loss: 145.711792  [  100/ 1485]\n",
      "loss: 17.260044  [  200/ 1485]\n",
      "loss: 133.362579  [  300/ 1485]\n",
      "loss: 393.631958  [  400/ 1485]\n",
      "loss: 84.936592  [  500/ 1485]\n",
      "loss: 52.703259  [  600/ 1485]\n",
      "loss: 113.523743  [  700/ 1485]\n",
      "loss: 154.050812  [  800/ 1485]\n",
      "loss: 59.188248  [  900/ 1485]\n",
      "loss: 223.251129  [ 1000/ 1485]\n",
      "loss: 142.548691  [ 1100/ 1485]\n",
      "loss: 80.901543  [ 1200/ 1485]\n",
      "loss: 65.537445  [ 1300/ 1485]\n",
      "loss: 245.271088  [ 1400/ 1485]\n",
      "Test Error: \n",
      " Accuracy: 0.0%, Avg loss: 161.783226 \n",
      "\n",
      "Epoch 14\n",
      "-------------------------------\n",
      "loss: 163.438889  [    0/ 1485]\n",
      "loss: 160.984100  [  100/ 1485]\n",
      "loss: 93.089203  [  200/ 1485]\n",
      "loss: 59.557999  [  300/ 1485]\n",
      "loss: 82.897690  [  400/ 1485]\n",
      "loss: 36.850185  [  500/ 1485]\n",
      "loss: 131.402435  [  600/ 1485]\n",
      "loss: 98.770912  [  700/ 1485]\n",
      "loss: 277.748779  [  800/ 1485]\n",
      "loss: 150.001740  [  900/ 1485]\n",
      "loss: 96.516708  [ 1000/ 1485]\n",
      "loss: 170.179062  [ 1100/ 1485]\n",
      "loss: 29.916245  [ 1200/ 1485]\n",
      "loss: 379.368561  [ 1300/ 1485]\n",
      "loss: 113.393951  [ 1400/ 1485]\n",
      "Test Error: \n",
      " Accuracy: 0.0%, Avg loss: 161.493372 \n",
      "\n",
      "Epoch 15\n",
      "-------------------------------\n",
      "loss: 84.438538  [    0/ 1485]\n",
      "loss: 332.005798  [  100/ 1485]\n",
      "loss: 65.681732  [  200/ 1485]\n",
      "loss: 219.419434  [  300/ 1485]\n",
      "loss: 104.339600  [  400/ 1485]\n",
      "loss: 97.621712  [  500/ 1485]\n",
      "loss: 128.524811  [  600/ 1485]\n",
      "loss: 83.806076  [  700/ 1485]\n",
      "loss: 139.194305  [  800/ 1485]\n",
      "loss: 33.060272  [  900/ 1485]\n",
      "loss: 39.353638  [ 1000/ 1485]\n",
      "loss: 105.146591  [ 1100/ 1485]\n",
      "loss: 140.872787  [ 1200/ 1485]\n",
      "loss: 226.724777  [ 1300/ 1485]\n",
      "loss: 118.212311  [ 1400/ 1485]\n",
      "Test Error: \n",
      " Accuracy: 0.0%, Avg loss: 161.536215 \n",
      "\n",
      "Epoch 16\n",
      "-------------------------------\n",
      "loss: 210.367371  [    0/ 1485]\n",
      "loss: 265.306885  [  100/ 1485]\n",
      "loss: 105.113586  [  200/ 1485]\n",
      "loss: 34.065224  [  300/ 1485]\n",
      "loss: 298.707764  [  400/ 1485]\n",
      "loss: 63.642155  [  500/ 1485]\n",
      "loss: 164.526779  [  600/ 1485]\n",
      "loss: 99.784897  [  700/ 1485]\n",
      "loss: 134.140076  [  800/ 1485]\n",
      "loss: 166.473846  [  900/ 1485]\n",
      "loss: 105.482094  [ 1000/ 1485]\n",
      "loss: 76.922913  [ 1100/ 1485]\n",
      "loss: 124.560654  [ 1200/ 1485]\n",
      "loss: 372.420532  [ 1300/ 1485]\n",
      "loss: 22.140699  [ 1400/ 1485]\n",
      "Test Error: \n",
      " Accuracy: 0.0%, Avg loss: 163.165340 \n",
      "\n",
      "Epoch 17\n",
      "-------------------------------\n",
      "loss: 90.952759  [    0/ 1485]\n",
      "loss: 95.694305  [  100/ 1485]\n",
      "loss: 27.708334  [  200/ 1485]\n",
      "loss: 49.982101  [  300/ 1485]\n",
      "loss: 11.233204  [  400/ 1485]\n",
      "loss: 446.301361  [  500/ 1485]\n",
      "loss: 68.439590  [  600/ 1485]\n",
      "loss: 217.388031  [  700/ 1485]\n",
      "loss: 187.545959  [  800/ 1485]\n",
      "loss: 127.329559  [  900/ 1485]\n",
      "loss: 359.656982  [ 1000/ 1485]\n",
      "loss: 179.620850  [ 1100/ 1485]\n",
      "loss: 60.717381  [ 1200/ 1485]\n",
      "loss: 249.331970  [ 1300/ 1485]\n",
      "loss: 121.045670  [ 1400/ 1485]\n",
      "Test Error: \n",
      " Accuracy: 0.0%, Avg loss: 161.831777 \n",
      "\n",
      "Epoch 18\n",
      "-------------------------------\n",
      "loss: 34.838203  [    0/ 1485]\n",
      "loss: 144.911438  [  100/ 1485]\n",
      "loss: 52.731277  [  200/ 1485]\n",
      "loss: 81.499306  [  300/ 1485]\n",
      "loss: 63.150414  [  400/ 1485]\n",
      "loss: 105.737305  [  500/ 1485]\n",
      "loss: 160.333466  [  600/ 1485]\n",
      "loss: 124.510262  [  700/ 1485]\n",
      "loss: 66.267227  [  800/ 1485]\n",
      "loss: 100.798210  [  900/ 1485]\n",
      "loss: 271.458679  [ 1000/ 1485]\n",
      "loss: 143.216370  [ 1100/ 1485]\n",
      "loss: 148.402283  [ 1200/ 1485]\n",
      "loss: 25.174877  [ 1300/ 1485]\n",
      "loss: 175.146545  [ 1400/ 1485]\n",
      "Test Error: \n",
      " Accuracy: 0.0%, Avg loss: 162.280561 \n",
      "\n",
      "Epoch 19\n",
      "-------------------------------\n",
      "loss: 129.396500  [    0/ 1485]\n",
      "loss: 132.263351  [  100/ 1485]\n",
      "loss: 167.408707  [  200/ 1485]\n",
      "loss: 39.337837  [  300/ 1485]\n",
      "loss: 8.218896  [  400/ 1485]\n",
      "loss: 114.706505  [  500/ 1485]\n",
      "loss: 51.932266  [  600/ 1485]\n",
      "loss: 197.830032  [  700/ 1485]\n",
      "loss: 323.731720  [  800/ 1485]\n",
      "loss: 21.516388  [  900/ 1485]\n",
      "loss: 70.774117  [ 1000/ 1485]\n",
      "loss: 170.927521  [ 1100/ 1485]\n",
      "loss: 59.386589  [ 1200/ 1485]\n",
      "loss: 287.190857  [ 1300/ 1485]\n",
      "loss: 99.343575  [ 1400/ 1485]\n",
      "Test Error: \n",
      " Accuracy: 0.0%, Avg loss: 161.729486 \n",
      "\n",
      "Epoch 20\n",
      "-------------------------------\n",
      "loss: 88.293228  [    0/ 1485]\n",
      "loss: 67.732132  [  100/ 1485]\n",
      "loss: 88.641464  [  200/ 1485]\n",
      "loss: 190.296494  [  300/ 1485]\n",
      "loss: 14.828218  [  400/ 1485]\n",
      "loss: 85.344574  [  500/ 1485]\n",
      "loss: 113.073746  [  600/ 1485]\n",
      "loss: 49.804108  [  700/ 1485]\n",
      "loss: 305.240540  [  800/ 1485]\n",
      "loss: 27.834293  [  900/ 1485]\n",
      "loss: 262.199829  [ 1000/ 1485]\n",
      "loss: 106.145607  [ 1100/ 1485]\n",
      "loss: 309.949982  [ 1200/ 1485]\n",
      "loss: 26.067646  [ 1300/ 1485]\n",
      "loss: 2.359748  [ 1400/ 1485]\n",
      "Test Error: \n",
      " Accuracy: 0.0%, Avg loss: 161.382608 \n",
      "\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "epochs = 20\n",
    "\n",
    "for t in range(epochs):\n",
    "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
    "    train(train_dl, model, loss_fn, optimizer)\n",
    "    test(test_dl, model, loss_fn)\n",
    "print(\"Done!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.13 ('.venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "c8b51c3fd42ce6209260a97a65ff50cb699cec9931c911d19bbbd2aaed9b45ec"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
